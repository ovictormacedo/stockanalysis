{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c8cf003-31a7-4cec-b728-9bc9526f87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  23 of 23 completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.float_format = '{:.4%}'.format\n",
    "\n",
    "params = json.loads(open('../params.json', 'r').read())\n",
    "\n",
    "# Date range\n",
    "start = \"2018-01-01\"\n",
    "end = \"2023-11-01\"\n",
    "\n",
    "# Tickers of assets\n",
    "industry_asset = json.loads(open('../stocks.json', 'r').read())\n",
    "assets = []\n",
    "for key, values in industry_asset.items():\n",
    "    for value in values:\n",
    "        assets.append(value)\n",
    "\n",
    "# Downloading data\n",
    "data = yf.download(assets, start=start, end=end, interval=\"1wk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "418a126a-4bf6-4041-88d4-e9292e67933f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "911ba613-843f-4eef-b6d1-175a9d9cc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta import trend, volume as volume_ta, momentum\n",
    "\n",
    "THRESHOLD = 10\n",
    "\n",
    "def get_trend(data_prices, i):\n",
    "    trend = float(0.5)\n",
    "    if 100 * (data_prices[i] / data_prices[i-1]) - 100 >= THRESHOLD:\n",
    "        trend = float(1.0)\n",
    "    elif 100 * (data_prices[i] / data_prices[i-1]) - 100 <= 0:\n",
    "        trend = float(0.0)\n",
    "    return trend\n",
    "\n",
    "def get_trend_open(data_open, data_close, i):\n",
    "    trend = float(0.5)\n",
    "    if 100 * (data_open[i] / data_close[i-1]) - 100 >= THRESHOLD:\n",
    "        trend = float(1.0)\n",
    "    elif 100 * (data_open[i] / data_close[i-1]) - 100 <= 0:\n",
    "        trend = float(0.0)\n",
    "    return trend\n",
    "\n",
    "def is_the_last_date(i, size):\n",
    "    return i == size-1\n",
    "\n",
    "indicators = {\n",
    "    asset: {\n",
    "        \"date\": [],\n",
    "        \"trend_open\": [],\n",
    "        \"trend_close\": [],\n",
    "        \"trend_high\": [],\n",
    "        \"trend_low\": [],\n",
    "        \"next_trend_open\": [],\n",
    "        \"next_trend_close\": [],\n",
    "        \"next_trend_high\": [],\n",
    "        \"next_trend_low\": [],\n",
    "        \"aroon\": [],\n",
    "        \"aroon_down\": [],\n",
    "        \"aroon_up\": [],\n",
    "        \"cmf\": [],\n",
    "        \"mfi\": [],\n",
    "        \"ppo\": [],\n",
    "        \"pvo\": [],\n",
    "        \"rsi\": [],\n",
    "        \"stc\": [],\n",
    "        \"volume_rsi\": [], \n",
    "        \"williamsr\": []\n",
    "    }\n",
    "    for asset in assets\n",
    "}\n",
    "dates = [d.to_pydatetime().strftime('%Y-%m-%d %H:%M:%S') for d in data.index]\n",
    "\n",
    "for asset in assets:\n",
    "    if int(dates[0][0:4]) > 2018:\n",
    "        print(f\"{int(dates[0][0:4])} is too new, skipping it.\")\n",
    "        continue\n",
    "\n",
    "    high = data[\"High\"][asset].astype(float)\n",
    "    low = data[\"Low\"][asset].astype(float)\n",
    "    open = data[\"Open\"][asset].astype(float)\n",
    "    close = data[\"Close\"][asset].astype(float)\n",
    "    volume = data[\"Volume\"][asset].astype(float)\n",
    "\n",
    "    # AROON indicator\n",
    "    aroon = trend.AroonIndicator(high, low).aroon_indicator()\n",
    "    aroon_down = trend.AroonIndicator(high, low).aroon_down()\n",
    "    aroon_up = trend.AroonIndicator(high, low).aroon_up()\n",
    "\n",
    "    # CMF indicator\n",
    "    indicator_calc = volume_ta.ChaikinMoneyFlowIndicator(high, low, close, volume)\n",
    "    cmf = indicator_calc.chaikin_money_flow()\n",
    "\n",
    "    # MFI indicator\n",
    "    mfi = volume_ta.MFIIndicator(high, low, close, volume).money_flow_index()\n",
    "\n",
    "    # PPO indicator\n",
    "    indicator_calc = momentum.PercentagePriceOscillator(close)\n",
    "    ppo = indicator_calc.ppo()\n",
    "    ppo_signal = indicator_calc.ppo_signal()\n",
    "\n",
    "    # PVO indicator\n",
    "    indicator_calc = momentum.PercentageVolumeOscillator(volume)\n",
    "    pvo = indicator_calc.pvo()\n",
    "    pvo_signal = indicator_calc.pvo_signal()\n",
    "\n",
    "    # RSI indicator\n",
    "    rsi = momentum.RSIIndicator(close).rsi()\n",
    "\n",
    "    # STC indicator\n",
    "    stc = trend.STCIndicator(close, 12, 5, 3, 3, 3).stc()\n",
    "\n",
    "    # VOLUME RSI indicator\n",
    "    volume_rsi = momentum.RSIIndicator(volume).rsi()\n",
    "\n",
    "    # WILLIAMS R indicator\n",
    "    williamsr = momentum.WilliamsRIndicator(high, low, close).williams_r()\n",
    "\n",
    "    data_len = len(williamsr)\n",
    "\n",
    "    first_not_nan = True\n",
    "    for i in range(1, data_len):\n",
    "        if (\n",
    "            not np.isnan(aroon[i]) and\n",
    "            not np.isnan(aroon_up[i]) and\n",
    "            not np.isnan(aroon_down[i]) and\n",
    "            not np.isnan(cmf[i]) and\n",
    "            not np.isnan(mfi[i]) and\n",
    "            not np.isnan(ppo[i]) and\n",
    "            not np.isnan(pvo[i]) and\n",
    "            not np.isnan(rsi[i]) and\n",
    "            not np.isnan(stc[i]) and\n",
    "            not np.isnan(volume_rsi[i]) and\n",
    "            not np.isnan(williamsr[i]) and\n",
    "            not np.isnan(pvo_signal[i])\n",
    "        ):\n",
    "            if first_not_nan:\n",
    "                first_not_nan = False\n",
    "                continue\n",
    "\n",
    "            trend_high = get_trend(high, i)\n",
    "            trend_low = get_trend(low, i)\n",
    "            trend_open = get_trend_open(open, close, i)\n",
    "            trend_close = get_trend(close, i)\n",
    "\n",
    "            next_trend_high = float(0.0) if is_the_last_date(i, data_len) else get_trend(high, i+1)\n",
    "            next_trend_low = float(0.0) if is_the_last_date(i, data_len) else get_trend(low, i+1)\n",
    "            next_trend_open = float(0.0) if is_the_last_date(i, data_len) else get_trend_open(open, close, i+1)\n",
    "            next_trend_close = float(0.0) if is_the_last_date(i, data_len) else get_trend(close, i+1)\n",
    "\n",
    "                    : [],\n",
    "        \"trend_open\": [],\n",
    "        \"trend_close\": [],\n",
    "        \"trend_high\": [],\n",
    "        \"trend_low\": [],\n",
    "        \"next_trend_open\": [],\n",
    "        \"next_trend_close\": [],\n",
    "        \"next_trend_high\": [],\n",
    "        \"next_trend_low\": [],\n",
    "        \"aroon\": [],\n",
    "        \"aroon_down\": [],\n",
    "        \"aroon_up\": [],\n",
    "        \"cmf\": [],\n",
    "        \"mfi\": [],\n",
    "        \"ppo\": [],\n",
    "        \"pvo\": [],\n",
    "        \"rsi\": [],\n",
    "        \"stc\": [],\n",
    "        \"volume_rsi\": [], \n",
    "        \"williamsr\": []\n",
    "            indicators[asset][\"date\"].append(dates[i])\n",
    "            indicators[asset][\"date\"].append(dates[i])\n",
    "            indicators[asset].append([\n",
    "                ,\n",
    "                high[i],\n",
    "                low[i],\n",
    "                open[i],\n",
    "                close[i],\n",
    "                volume[i],\n",
    "                aroon[i],\n",
    "                aroon_down[i],\n",
    "                aroon_up[i],\n",
    "                cmf[i],\n",
    "                mfi[i],\n",
    "                ppo[i],\n",
    "                ppo_signal[i],\n",
    "                pvo[i],\n",
    "                pvo_signal[i],\n",
    "                rsi[i],\n",
    "                stc[i],\n",
    "                volume_rsi[i],\n",
    "                williamsr[i],\n",
    "                trend_high,\n",
    "                next_trend_high,\n",
    "                trend_low,\n",
    "                next_trend_low,\n",
    "                trend_open,\n",
    "                next_trend_open,\n",
    "                trend_close,\n",
    "                next_trend_close])\n",
    "\n",
    "            indicators[asset].sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5e39e-6b0a-4214-ac7e-32a431ddc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "keras = tf.keras\n",
    "layers = tf.keras.layers\n",
    "activations = tf.keras.activations\n",
    "\n",
    "# Receiving parameters\n",
    "OUTPUT_MODEL_PATH = \"trained-models/\"\n",
    "EPOCHS = 20000\n",
    "\n",
    "for asset in assets:\n",
    "    print(f\"Processing close {asset}\")\n",
    "\n",
    "    # Parse data\n",
    "    data = {\"date\":[], \"symbol\": [], \"aroon\": [], \"aroon_down\": [], \"aroon_up\": [], \"cmf\": [], \"mfi\": [], \"ppo\": [], \"pvo\": [], \"rsi\": [], \"stc\": [], \"volume_rsi\": [], \"williamsr\": [], \"trend_close\": [], \"next_trend_close\": [], \"trend_high\": [], \"trend_low\": [], \"trend_open\": []}\n",
    "    for index, row in data_df.iterrows():\n",
    "        data[\"date\"].append(row[\"date\"])\n",
    "        data[\"next_trend_close\"].append(row[\"next_trend_close\"])\n",
    "        data[\"trend_high\"].append(row[\"trend_high\"])\n",
    "        data[\"trend_low\"].append(row[\"trend_low\"])\n",
    "        data[\"trend_open\"].append(row[\"trend_open\"])\n",
    "        data[\"trend_close\"].append(row[\"trend_close\"])\n",
    "        data[\"aroon\"].append(row[\"aroon\"])\n",
    "        data[\"aroon_down\"].append(row[\"aroon_down\"])\n",
    "        data[\"aroon_up\"].append(row[\"aroon_up\"])\n",
    "        data[\"cmf\"].append(row[\"cmf\"])\n",
    "        data[\"mfi\"].append(row[\"mfi\"])\n",
    "        data[\"ppo\"].append(row[\"ppo\"])\n",
    "        data[\"pvo\"].append(row[\"pvo\"])\n",
    "        data[\"rsi\"].append(row[\"rsi\"])\n",
    "        data[\"stc\"].append(row[\"stc\"])\n",
    "        data[\"volume_rsi\"].append(row[\"volume_rsi\"])\n",
    "        data[\"williamsr\"].append(row[\"williamsr\"])\n",
    "\n",
    "    # Reshape data\n",
    "    data_reshaped = {\"trend_open\": [], \"trend_close\": [], \"trend_high\": [], \"trend_low\": [], \"aroon\": [], \"aroon_down\": [], \"aroon_up\": [], \"cmf\": [], \"mfi\": [], \"ppo\": [], \"pvo\": [], \"rsi\": [], \"stc\": [], \"volume_rsi\": [], \"williamsr\": []}\n",
    "    for index, row in data.items():\n",
    "        data_reshaped[index] = np.array(row)\n",
    "        data_reshaped[index] = data_reshaped[index].reshape(-1, 1)\n",
    "\n",
    "    # Create scalers\n",
    "    scalers = {\"trend_open\": None, \"trend_close\": None, \"trend_high\": None, \"trend_low\": None, \"aroon\": None, \"aroon_down\": None, \"aroon_up\": None, \"cmf\": None, \"mfi\": None, \"ppo\": None, \"pvo\": None, \"rsi\": None, \"stc\": None, \"volume_rsi\": None, \"williamsr\": None}\n",
    "    for index, row in scalers.items():\n",
    "        scalers[index] = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Discretize data\n",
    "    data_scaled = {\"aroon\": [], \"aroon_down\": [], \"aroon_up\": [], \"cmf\": [], \"mfi\": [], \"ppo\": [], \"pvo\": [], \"rsi\": [], \"stc\": [], \"volume_rsi\": [], \"williamsr\": []}\n",
    "    for index, row in data_reshaped.items():\n",
    "        if index not in [\"next_trend_close\", \"date\", \"symbol\"]:\n",
    "            data_scaled[index] = scalers[index].fit_transform(data_reshaped[index])\n",
    "\n",
    "    processed_data = []\n",
    "    ticker_date = data[\"date\"][-1]\n",
    "    number_of_lines = len(data_scaled[\"aroon\"])\n",
    "    for i in range(0, number_of_lines):\n",
    "        if ticker_date == data[\"date\"][i]:\n",
    "            break\n",
    "\n",
    "        processed_data.append([\n",
    "            data[\"date\"][i],\n",
    "            [data[\"next_trend_close\"][i]],\n",
    "            data_scaled[\"trend_high\"][i],\n",
    "            data_scaled[\"trend_low\"][i],\n",
    "            data_scaled[\"trend_open\"][i],\n",
    "            data_scaled[\"trend_close\"][i],\n",
    "            data_scaled[\"aroon\"][i],\n",
    "            data_scaled[\"aroon_down\"][i],\n",
    "            data_scaled[\"aroon_up\"][i],\n",
    "            data_scaled[\"cmf\"][i],\n",
    "            data_scaled[\"mfi\"][i],\n",
    "            data_scaled[\"ppo\"][i],\n",
    "            data_scaled[\"pvo\"][i],\n",
    "            data_scaled[\"rsi\"][i],\n",
    "            data_scaled[\"stc\"][i],\n",
    "            data_scaled[\"williamsr\"][i]\n",
    "        ])\n",
    "\n",
    "    # Model training\n",
    "    train_input_data_x = np.array([d[2:] for d in processed_data])\n",
    "    train_input_data_y = np.array([d[1:2] for d in processed_data])\n",
    "\n",
    "    # Define Sequential model\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(len(train_input_data_x[0]), input_shape=(len(train_input_data_x[0]),), activation=\"sigmoid\", name=\"layer1\"))\n",
    "    model.add(layers.Dense(20, activation=\"sigmoid\", name=\"layer2\"))\n",
    "    model.add(layers.Dense(10, activation=\"sigmoid\", name=\"layer3\"))\n",
    "    model.add(layers.Dense(1, name=\"layer4\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "        # Loss function to minimize\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "\n",
    "    model_trained = model.fit(\n",
    "        train_input_data_x,\n",
    "        train_input_data_y,\n",
    "        batch_size=512,\n",
    "        epochs=int(EPOCHS)\n",
    "    )\n",
    "\n",
    "    model.save(OUTPUT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce399190-90fa-4dda-9384-123a2eef5c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
